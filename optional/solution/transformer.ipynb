{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(batch = 4):\n",
    "    t = np.arange(0,torch.randint(3,15,(1,)),step=0.1)\n",
    "    X = torch.zeros(batch,t.size,1)\n",
    "    Y = torch.zeros(batch,2)\n",
    "    for i in range(batch):\n",
    "        a = torch.rand(1)*3 + 0.1\n",
    "        b = torch.rand(1)*4 + 0.2\n",
    "        #X[i,:,0] =  torch.tensor(t)\n",
    "        X[i,:,0] =  a*np.sin(b*t)\n",
    "        Y[i,0],Y[i,1] = a,b\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "class TransformerRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nhead, hidden_dim, num_layers):\n",
    "        super(TransformerRegression, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        encoder_layer = TransformerEncoderLayer(hidden_dim, nhead)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # Изменяем форму для передачи в трансформер\n",
    "        output = self.encoder(x)  # Применяем трансформер\n",
    "        #print(output.shape)\n",
    "        #output = output.mean(dim=0)  # Усредняем по временным шагам\n",
    "        output = output[0,:,:]\n",
    "        output = self.fc(output)  # Полносвязный слой для предсказания\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strike/penv/deep/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 1\n",
    "output_dim = 2\n",
    "nhead = 2#4\n",
    "hidden_dim = 32\n",
    "num_layers = 2#4\n",
    "\n",
    "model = TransformerRegression(input_dim, output_dim, nhead, hidden_dim, num_layers)\n",
    "#model.load_state_dict(torch.load('models/transf_expect_2head_2layer'))\n",
    "#model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = gen_data(batch=2)\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 0.4356\n",
      "Epoch [200/4000], Loss: 0.4278\n",
      "Epoch [300/4000], Loss: 0.4218\n",
      "Epoch [400/4000], Loss: 0.4266\n",
      "Epoch [500/4000], Loss: 0.4475\n",
      "Epoch [600/4000], Loss: 0.4374\n",
      "Epoch [700/4000], Loss: 0.4007\n",
      "Epoch [800/4000], Loss: 0.3994\n",
      "Epoch [900/4000], Loss: 0.4186\n",
      "Epoch [1000/4000], Loss: 0.4186\n",
      "Epoch [1100/4000], Loss: 0.4368\n",
      "Epoch [1200/4000], Loss: 0.3938\n",
      "Epoch [1300/4000], Loss: 0.4391\n",
      "Epoch [1400/4000], Loss: 0.4264\n",
      "Epoch [1500/4000], Loss: 0.4302\n",
      "Epoch [1600/4000], Loss: 0.3814\n",
      "Epoch [1700/4000], Loss: 0.4001\n",
      "Epoch [1800/4000], Loss: 0.3999\n",
      "Epoch [1900/4000], Loss: 0.3975\n",
      "Epoch [2000/4000], Loss: 0.3896\n",
      "Epoch [2100/4000], Loss: 0.4270\n",
      "Epoch [2200/4000], Loss: 0.4348\n",
      "Epoch [2300/4000], Loss: 0.4220\n",
      "Epoch [2400/4000], Loss: 0.3974\n",
      "Epoch [2500/4000], Loss: 0.3908\n",
      "Epoch [2600/4000], Loss: 0.4018\n",
      "Epoch [2700/4000], Loss: 0.3883\n",
      "Epoch [2800/4000], Loss: 0.3854\n",
      "Epoch [2900/4000], Loss: 0.4045\n",
      "Epoch [3000/4000], Loss: 0.3782\n",
      "Epoch [3100/4000], Loss: 0.3922\n",
      "Epoch [3200/4000], Loss: 0.4010\n",
      "Epoch [3300/4000], Loss: 0.3900\n",
      "Epoch [3400/4000], Loss: 0.3901\n",
      "Epoch [3500/4000], Loss: 0.4318\n",
      "Epoch [3600/4000], Loss: 0.3706\n",
      "Epoch [3700/4000], Loss: 0.4066\n",
      "Epoch [3800/4000], Loss: 0.4055\n",
      "Epoch [3900/4000], Loss: 0.3771\n",
      "Epoch [4000/4000], Loss: 0.3898\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "s = []\n",
    "# Обучение модели\n",
    "num_epochs = 4000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x,y = gen_data(batch=16)\n",
    "    output = model(x.to(device))\n",
    "    \n",
    "    loss = criterion(output, y.to(device))  # Используем только первый измерение для задачи регрессии\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    l = loss.detach().to('cpu')\n",
    "    s.append(l)\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        L = np.mean(s)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {L:.4f}')\n",
    "        s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.4408, 2.5631]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[1.5181, 2.2340]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = gen_data(batch=1)\n",
    "output = model(x)\n",
    "output, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
